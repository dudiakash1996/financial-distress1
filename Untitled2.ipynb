{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in b:\\downloads\\anaconda\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in b:\\downloads\\anaconda\\lib\\site-packages (from imblearn) (0.3.3)\n",
      "Requirement already satisfied: scikit-learn in b:\\downloads\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (0.19.1)\n",
      "Requirement already satisfied: scipy in b:\\downloads\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: numpy in b:\\downloads\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.14.3)\n"
     ]
    }
   ],
   "source": [
    "# To supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#!pip install msgpack-python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#!pip install pickle  --upgrade pip\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# For loading .arff files\n",
    "from scipy.io import arff\n",
    "\n",
    "# To perform mean imputation\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Formatted counter of class labels\n",
    "from collections import Counter\n",
    "# Ordered Dictionary\n",
    "from collections import OrderedDict\n",
    "#To perform kFold Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Library imbalanced-learn to deal with the data imbalance. To use SMOTE oversampling\n",
    "!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# Impoting classification models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, meta1 = arff.loadarff('1year.arff');\n",
    "df1 = pd.DataFrame(df1);\n",
    "def set_new_headers(dataframes):\n",
    "    cols = ['X' + str(i+1) for i in range(len(dataframes.columns)-1)]\n",
    "    cols.append('Y')\n",
    "    dataframes.columns = cols\n",
    "set_new_headers(df1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200550</td>\n",
       "      <td>0.37951</td>\n",
       "      <td>0.39641</td>\n",
       "      <td>2.0472</td>\n",
       "      <td>32.3510</td>\n",
       "      <td>0.38825</td>\n",
       "      <td>0.249760</td>\n",
       "      <td>1.33050</td>\n",
       "      <td>1.1389</td>\n",
       "      <td>0.50494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121960</td>\n",
       "      <td>0.39718</td>\n",
       "      <td>0.87804</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>8.4160</td>\n",
       "      <td>5.1372</td>\n",
       "      <td>82.658</td>\n",
       "      <td>4.4158</td>\n",
       "      <td>7.4277</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.49988</td>\n",
       "      <td>0.47225</td>\n",
       "      <td>1.9447</td>\n",
       "      <td>14.7860</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.258340</td>\n",
       "      <td>0.99601</td>\n",
       "      <td>1.6996</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.42002</td>\n",
       "      <td>0.85300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.1486</td>\n",
       "      <td>3.2732</td>\n",
       "      <td>107.350</td>\n",
       "      <td>3.4000</td>\n",
       "      <td>60.9870</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248660</td>\n",
       "      <td>0.69592</td>\n",
       "      <td>0.26713</td>\n",
       "      <td>1.5548</td>\n",
       "      <td>-1.1523</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.309060</td>\n",
       "      <td>0.43695</td>\n",
       "      <td>1.3090</td>\n",
       "      <td>0.30408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241140</td>\n",
       "      <td>0.81774</td>\n",
       "      <td>0.76599</td>\n",
       "      <td>0.694840</td>\n",
       "      <td>4.9909</td>\n",
       "      <td>3.9510</td>\n",
       "      <td>134.270</td>\n",
       "      <td>2.7185</td>\n",
       "      <td>5.2078</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081483</td>\n",
       "      <td>0.30734</td>\n",
       "      <td>0.45879</td>\n",
       "      <td>2.4928</td>\n",
       "      <td>51.9520</td>\n",
       "      <td>0.14988</td>\n",
       "      <td>0.092704</td>\n",
       "      <td>1.86610</td>\n",
       "      <td>1.0571</td>\n",
       "      <td>0.57353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054015</td>\n",
       "      <td>0.14207</td>\n",
       "      <td>0.94598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5746</td>\n",
       "      <td>3.6147</td>\n",
       "      <td>86.435</td>\n",
       "      <td>4.2228</td>\n",
       "      <td>5.5497</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.61323</td>\n",
       "      <td>0.22960</td>\n",
       "      <td>1.4063</td>\n",
       "      <td>-7.3128</td>\n",
       "      <td>0.18732</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.63070</td>\n",
       "      <td>1.1559</td>\n",
       "      <td>0.38677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134850</td>\n",
       "      <td>0.48431</td>\n",
       "      <td>0.86515</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>6.3985</td>\n",
       "      <td>4.3158</td>\n",
       "      <td>127.210</td>\n",
       "      <td>2.8692</td>\n",
       "      <td>7.8980</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2       X3      X4       X5       X6        X7       X8  \\\n",
       "0  0.200550  0.37951  0.39641  2.0472  32.3510  0.38825  0.249760  1.33050   \n",
       "1  0.209120  0.49988  0.47225  1.9447  14.7860  0.00000  0.258340  0.99601   \n",
       "2  0.248660  0.69592  0.26713  1.5548  -1.1523  0.00000  0.309060  0.43695   \n",
       "3  0.081483  0.30734  0.45879  2.4928  51.9520  0.14988  0.092704  1.86610   \n",
       "4  0.187320  0.61323  0.22960  1.4063  -7.3128  0.18732  0.187320  0.63070   \n",
       "\n",
       "       X9      X10  ...        X56      X57      X58       X59     X60  \\\n",
       "0  1.1389  0.50494  ...   0.121960  0.39718  0.87804  0.001924  8.4160   \n",
       "1  1.6996  0.49788  ...   0.121300  0.42002  0.85300  0.000000  4.1486   \n",
       "2  1.3090  0.30408  ...   0.241140  0.81774  0.76599  0.694840  4.9909   \n",
       "3  1.0571  0.57353  ...   0.054015  0.14207  0.94598  0.000000  4.5746   \n",
       "4  1.1559  0.38677  ...   0.134850  0.48431  0.86515  0.124440  6.3985   \n",
       "\n",
       "      X61      X62     X63      X64     Y  \n",
       "0  5.1372   82.658  4.4158   7.4277  b'0'  \n",
       "1  3.2732  107.350  3.4000  60.9870  b'0'  \n",
       "2  3.9510  134.270  2.7185   5.2078  b'0'  \n",
       "3  3.6147   86.435  4.2228   5.5497  b'0'  \n",
       "4  4.3158  127.210  2.8692   7.8980  b'0'  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dtypes of all the columns (other than the class label columns) to float.\n",
    "def convert_columns_type_float(dfs):\n",
    "    index = 1\n",
    "    while(index<=63):\n",
    "        colname = dfs.columns[index]\n",
    "        col = getattr(dfs, colname)\n",
    "        dfs[colname] = col.astype(float)\n",
    "        index+=1\n",
    "\n",
    "convert_columns_type_float(df1)\n",
    "\n",
    "\n",
    "# The class labels for all the dataframes are originally in object type.\n",
    "# Convert them to int types\n",
    "def convert_class_label_type_int(dfs):\n",
    "    col = getattr(dfs, 'Y')\n",
    "    dfs['Y'] = col.astype(int)\n",
    "        \n",
    "convert_class_label_type_int(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length= 7027 \tCleaned Length= 3194 \tMissing Data= 3833\n"
     ]
    }
   ],
   "source": [
    "# Get Clean dataframes by dropping all the rows which have missing values\n",
    "def drop_nan_rows(dataframes, verbose=False):\n",
    "    clean_dataframes = dataframes.dropna(axis=0, how='any')\n",
    "    if verbose:\n",
    "        print('Original Length=', len(dataframes), '\\tCleaned Length=', len(clean_dataframes), '\\tMissing Data=', len(dataframes)-len(clean_dataframes))\n",
    "    return clean_dataframes\n",
    "\n",
    "# Doing a quick analysis of how many missing values are there in each of the 5 dataframes\n",
    "nan_dropped_dataframes = drop_nan_rows(df1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_mean_imputation(dfs):\n",
    "    # Construct an imputer with strategy as 'mean', to mean-impute along the columns\n",
    "    imputer = Imputer(missing_values=np.nan, strategy='mean', axis=0)\n",
    "    mean_imputed_dfs = pd.DataFrame(imputer.fit_transform(dfs))\n",
    "    mean_imputed_dfs.columns = dfs.columns   \n",
    "    return mean_imputed_dfs\n",
    "\n",
    "mean_imputed_dataframes = perform_mean_imputation(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1styear\n",
      "Y\n",
      "0    6756\n",
      "1     271\n",
      "dtype: int64\n",
      "Minority (label 1) percentage: 3.856553294435748%\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def check_data_imbalance(dfs):\n",
    "    print('Dataset: '+str(1)+'styear')\n",
    "    print(dfs.groupby('Y').size())\n",
    "    minority_percent = (dfs['Y'].tolist().count(1) / len(dfs['Y'].tolist()))*100\n",
    "    print('Minority (label 1) percentage: '+  str(minority_percent) + '%')\n",
    "    print('-'*64)\n",
    "        \n",
    "check_data_imbalance(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features and labels into separate dataframes for all the original dataframes\n",
    "def split_dataframes_features_labels(dfs):\n",
    "    feature_dfs = dfs.iloc[:,0:64] \n",
    "    label_dfs = dfs.iloc[:,64]\n",
    "    return feature_dfs, label_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature,label = split_dataframes_features_labels(mean_imputed_dataframes)\n",
    "m1 = SMOTE()\n",
    "x,y = m1.fit_sample(feature,label)\n",
    "x = pd.DataFrame(x)\n",
    "y = pd.DataFrame(y)\n",
    "data = pd.concat([x,y],axis = 1)\n",
    "set_new_headers(data)\n",
    "data_feature = data.iloc[:,0:64] \n",
    "data_label = data.iloc[:,64:]\n",
    "data_feature_train,data_feature_test,data_label_train,data_label_test = train_test_split(data_feature,data_label,test_size = .3,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Bagging Classifier\n",
    "bb_classifier = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(criterion='entropy'), n_estimators = 10, bootstrap = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bb_classifier.fit(data_feature,data_label)\n",
    "predicted_data = y.predict(data_feature)\n",
    "predicted_data = pd.DataFrame(predicted_data)\n",
    "predicted_data.to_csv('predicted_data.csv',sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(bb_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998519834221433\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(data_feature, data_label)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
